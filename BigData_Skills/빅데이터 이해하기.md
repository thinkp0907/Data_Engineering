# 빅데이터 이해하기

## 빅데이터란?

> "빅데이터는 통상적으로 사용되는 데이터 수집 및 관리, 처리와 관련된 소프트웨어의 수용 한계를 넘어서는 크기의 데이터를 말하며, 빅데이터의 규모는 단일 데이터 집합의 크기가 수십 테라바이트에서 수 페타바이트에 이르며, 그 크기가 끊임없이 변화하는 것이 특징이다"

### 빅데이터의 정의

- 2011년 메타그룹(현 가트너)의 애널리스트인 더그 레이니(Doug Lane)의 `3V`로 정의 된다.
  - 크기(Volume)
  - 다양성(Variety)
  - 속도(Velocity)
- 이후 IBM이 **진실성(Veracity)**이라는 요소를 더해 `4V`를 정의했다
- 이후에 **시각화(Visualization)**, **가치(Value)**가 추가로 정의도면서 현재는 **`6V`**까지 확장됐다.



> **크기(Volume):** 방대한 양의 데이터(테라, 페타바이트 이상의 크기)
>
> **다양성(Variety):** 정형(DBMS, 전문 등) + 비정형(SNS, 동영상, 사진, 음성, 텍스트 등)
>
> **속도(Velocity):** 실시간으로 생산되며, 빠른 속도로 데이터를 처리/분석
>
> **진실성(Veracity):** 주요 의사결정을 위해 데이터의 품질과 신뢰성 확보
>
> **시각화(Visualization):** 복잡한 대규모 데이터를 시각적으로 표현
>
> **가치(Value):** 비지니스 효익을 실현하기 위해 궁극적인 가치를 창출

6V를 통해 빅데이터를 다음과 같이 정의할 수 있다.

"지구상에선 지금 이순간에도 방대한 **크기**의 **다양한** 데이터들이 빠른 **속도**로 발생하고 있다. 빅데이터는 *3V*를 수용하며, 데이터의 **진실성**을 확보하고, 분석 데이터를 **시각화**함으로써 새로운 효익을 가져다 줄 **가치**를 창출하는 것이다."



### 빅데이터의 목적

- 빅데이터의 목적은 **''빅데이터 인사이트''** 이다.
- 성공적인 빅데이터 시스템의 구축과 운영을 위해서는 세 가지 요소로 `사람`, `기술`,`데이터`가 필요하다
- 시스템 구축 이후 빅데이터에서 인사이트를 발견하여 **비용 절감**, **수익 창출**, **문제 해결**을 달성하는 것이 최종적인 목적이다.
- 빅데이터 인사이트에는 세 가지 유형이 있다.
  - 현상 이해: 대규모 데이터로부터 통계량을 추출해 과거에 발생한 일에 대한 이해와 원일 파악
  - 현상 발견: 지금까지 알지 못했던 데이터 패턴들을 발견, 해석해 무슨 일이 새롭게 일어났는지 발견
  - 현상 예측: 이해와 발견을 기반으로 예측 모형(모델)을 만들고, 현재 발생하고 있는 데이터를 모형에 입력해 미래에 발생할 현상 예측.



### 빅데이터 프로젝트

빅데이터 프로젝트는 크게 세 가지 유형으로 나눌 수 있다.

- 플랫폼 구축형 프로젝트
- 빅데이터 분석 프로젝트
- 빅데이터 운영 프로젝트



#### 1. 플랫폼 구축형 프로젝트

플랫폼 구축 프로젝트는 전형적인 빅데이터 SI(System Integration) 구축형 사업이다. 빅데이터의 하드웨어와 소프트웨어를 설치 및 구성하고 빅데이터의 기본 프로세스인 수집-> 적재-> 처리-> 탐색-> 분석의 기능을 구성한다.

#### 2. 빅데이터 분석 프로젝트

빅데이터 분석 프로젝트는 플랫폼 구축 완료 후 6~12개월 정도 데이터를 모으면서 데이터에 대한 이해가 높아지기 시작할 때 진행한다. 관련한 분석 프로젝트의 주제 영역을 크게 세 가지로 분류할 수 있다.

- **마케팅 분석 영역:** 주로 고객 분석을 통해 차별화된 맞춤 전략을 수립하는 데 활용
- **상품/서비스 분석 영역:** 신규 BM을 개발할 때 다양한 상품/서비스의 속성(가격, 디자인, 타겟팅, 출시일 등)을 결정하는데 활용되는 영역
- **리스크 분석 영역:** 기업을 운영할 때 매우 다양한 내/외부 리스크가 존재하는데 이러한 리스크를 사전에 예방 및 예측하는데 활용

#### 3. 빅데이터 운영 프로젝트

완성된 빅데이터 시스템을 중장기적으로 유지 관리하는 프로젝트로, 기존의 다른 운영 시스템들과 비교시 상당한 노력과 운영비용이 발생한다. 빅데이터 시스템은 다양한 하드웨어와 수십여종의 오픈소스 소프트웨어로 구성된 대규모 분산플랫폼으로 매일 다양한 기술적 이슈와 장애 발생을 인정 해야 하며, 이를 해결하기 위한 H/W, S/W 업그레이드 및 패치 작업이 매우 빈번

|   유형    | 플랫폼 구축형 프로젝트                                       | 빅데이터 분석 프로젝트                                       | 빅데이터 운영 프로젝트                                       |
| :-------: | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 구축 기간 | 보통 3~6개월                                                 | 1~3개월/ 빅데이터 분석이 필요한 시점에                       | 상당한 노력과 운영비용이 발생한다.                           |
| 조직 파트 | 플랫폼 파트/ 전처리 파트/ 후처리 파트                        | 비지니스 전문가/데이터 분석/ 데이터 엔지니어링               | 빅데이터 센터/빅데이터 분석팀/빅데이터 플랫폼 팀             |
|   비고    | 상당 시간이 내/외부 데이터 수집/적재에 사용. 수년간 백업돼 있는 데이터의 마이그레이션과 주변 업무 시스템에서 발생하는 데이터의 양과 속성에 따라 프로젝트 기간이 크게 늘어난다. | 정해진 바는 없지만 업무부서와 IT부서가 50:50의 비율로 참여해 엄무와 기술이 조화를 이루도록 역활을 구성하는 것이 매우 중요하다. | 빅데이터를 잘하려면 기술과 비지니스 분야에서 전문가 그룹이 반드시 필요한데, 이를 내재화 하지 않고 일련의 시스템처럼 외주 또는 ITO에 의존시 곧바로 한계에 부딪치게 된다. |



### 빅데이터 구현 기술

빅데이터 아키텍처는 역할별로 수집, 적재, 처리 및 탐색, 분석 및 응용이라는 6개의 레이어로 나눌 수 있다

| 단계 |                             역할                             |                           활용기술                           |                    |
| ---- | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------: |
| 수집 |         내/외부 데이터 연동<br />내/외부 데이터 통합         | Crawling, FTP, Open API, RSS, LOG Aggregation DB AGGregation, Streaming |       전처리       |
| 적재 |     대용량/실시간 데이터처리<br />분산 파일 시스템 저장      |    Distributed File, No-SQL, Memory Cached, MessageQueue/    |       전처리       |
| 처리 | 데이터 선택, 변환, 통합, 축소<br />데이터 워크플로 및 자동화 | Structured Processing, Unstructured Processing, Workflow, Scheduler | 전처리<br />후처리 |
| 탐색 |          대화형 데이터 질의<br />탐색적 Ad-Hoc분석           | SQL Like, Distributed Programming, Exploration Visualization |       후처리       |
| 분석 |         빅데이터 마트 구성<br />통계 분석, 고급 분석         |    Data Mining, Machine Learning, Analysis Visualization     |       후처리       |
| 응용 |             보고서 및 시각화<br />분석 정보 제공             |    Data Export/Import, Reporting, Business Visualization     |        활용        |



구축 순서도 통상 수집 -> 적재 -> 처리 및 탐색 -> 분석 및 으용 순으로 진행되며, 이 가운데 3번째(처리 및 탐색)와 4번째(분석 및 응용) 단계는 필요 시 반복 진행하면서 데이터의 품질과 분석 수준을 향상시킨다.





#### 수집 기술

빅데이터의 수집 기술은 조직의 내외부에 있는 다양한 시스템으로부터 원천 데이터를 효과적으로 수집하는 기술이다. 빅데이터 수집에는 기존의 수집 시스템(EAI, ETL, ESB 등)에서 다뤘던 데이터 보다 더 크고 다양한 형식의 데이터를 빠르게 처리해야 하는 기능이 필요한데, 이 때문에 빅데이터 수집 아키텍처는 선형 확장이 가능하면서 분산 처리가 가능한 형태로 구성한다.

빅데이터 수집기는 원천 시스템의 다양한 인터페이스 유형(DB, 파일, API, 메시지 등)과 연결되어 정형 또는 비정형 데이터를 대용량으로 수집한다. 특히 외부 데이터(SNS, 블로그, 포털 등)를 수집할 때는 크롤링, NLP 등 비정형 처리를 위한 기술이 선택적으로 적용된다. 수집된 데이터는 필요 시 정제, 변환, 필터링 등의 작업을 

추가로 진행해 데이터의 품질을 향상시킨 후 빅데이터 저장소에 적재한다.



**[6V 관점의 빅데이터 수집 기술]**

| 6V            | 수집 기술                                                    | 중요성 |
| ------------- | ------------------------------------------------------------ | ------ |
| Volume        | 대용량 데이터(테라바이트 이상) 수집<br />대규모 메시지(1,000TPS 이상)수집 | 상     |
| Variety       | 정형/반정형/비정형 데이터 수집<br />예) Log, RSS, XML, 파일, DM, HTML, 음성, 사진, 동영상 등 | 상     |
| Velocity      | 실시간 스트림 데이터 수집                                    | 상     |
| Veracity      | N/A                                                          | 하     |
| Visualization | N/A                                                          | 하     |
| Value         | N/A                                                          | 하     |

빅데이터 수집 기술은 6V 관점에서 데이터의 크기, 다양성, 생성 속도를 효과적으로 처리하는 기능에 집중. 빅데이터 수집 관련 소프트웨어로는 Flume, Fluented, Scribe, Logstash, Chukwa, NiFi, Embulk 등이 있다.



#### 적재 기술

빅데이터 적재 기술은 수집한 데이터를 `분산 스토리지에` 영구 또는 임시로 적재하는 기술이다. 빅데이터의 분산 저장소로는 크게 4가지 유형이 있다. 

| 분산 저장소                                                  | 사용 이유                               |
| ------------------------------------------------------------ | --------------------------------------- |
| HDFS(Hadoop Distributed File System)                         | 대용량 파일 전체를 영구적으로 저장      |
| NoSQL(HBase, MongoDB, Casandra 등)                           | 대규모 메시징 데이터 전체를 영구 저장   |
| 인메모리 캐쉬(Redis, Memcached, Infinispan 등)               | 대규모 메시징 데이터의 일부만 임시 저장 |
| MoM(Message Oriented Middleware) (Kafka, RabbitMQ, ActiveMQ 등) | 대규모 메시징 데이터 전체를 버퍼링 처리 |

빅데이터 적재 기술은 수집된 데이터의 성격에 따라 적재 저장소를 달리하는데, 대용량 파일의 적재는 HDFS 저장소를 사용하면 되지만 실시간 및 대량으로 발생하는 작은 메시지 데이터를 HDFS에 저장할 경우 파일 수가 기하급수적으로 늘어나 효율성이 크게 떨어진다. 이를 보완하기 위해서는 데이터의 성격에 따라 NoSQL, 인메모리 캐시, MoM 등을 선택적으로 사용할 수 있는 아키텍처링이 이뤄져야 한다.



**[6V 관점의 빅데이터 적재 기술]**

| 6V            | 적재 기술                                                    | 중요성 |
| ------------- | ------------------------------------------------------------ | ------ |
| Volume        | 대용량 데이터(테라바이트 이상) 적재<br />대규모 메시지(1,000TPS 이상)적재 | 상     |
| Variety       | 정형/반정형/비정형 데이터 수집                               | 중     |
| Velocity      | 실시간 스트림 데이터 적재                                    | 상     |
| Veracity      | 데이터의 품질과 신뢰성을 확보해 적재                         | 상     |
| Visualization | N/A                                                          | 하     |
| Value         | N/A                                                          | 하     |

빅데이터 적재 기술은 6V 관점에서 데이터의 크기, 속도, 진실성을 효과적으로 처리해야 한다.



#### 처리/탐색 기술

빅데이터 처리/탐색 기술은 대용량 저장소에 적재된 데이터를 분석에 활용하기 위해 데이터를 정형화 및 정규화하는 기술이다. 데이터를 통해 가치를 발굴하기 위해서는 데이터를 이해하는 것이 선행돼야 하며, 이 과정에서 적재된 빅데이터를 지속적으로 관찰하는 `탐색적 분석`과 탐색 결과를 정기적으로 구조화하는 작업을 수행한다.

`탐색적 분석`에서는 SQL on Hadoop이 주로 사용되며, 대화형 애드혹(Ad-Hoc) 쿼리로 데이터를 탐색, 선택, 변환, 통합, 축소 등의 작업을 수행한다. 특히 내외부의 정형/비정형 데이터를 결합해 기존에 기술적 한계로 만들지 못했던 새로운 데이터셋을 생성하는 주요한 작업이 진행된다. 또한 정기적으로 발생하는 처리/탐색의 과정들은 workflow로 프로세스화해서 자동화하고, workflow로 작업이 끝나면 데이터셋들은 특화된 데이터 저장소(Data Warehouse, Mart등)로 옮겨진다.



**[6V 관점의 빅데이터 처리/탐색 기술]**

| 6V            | 처리/탐색 기술                                        | 중요성 |
| ------------- | ----------------------------------------------------- | ------ |
| Volume        | 대용량 데이터(테라바이트 이상)에 대한 후처리 및 탐색  | 상     |
| Variety       | N/A                                                   | 하     |
| Velocity      | N/A                                                   | 하     |
| Veracity      | 데이터의 품질과 신뢰성을 확보하기 위한 후처리 및 탐색 | 상     |
| Visualization | 후처리된 데이터셋을 시각화해서 탐색                   | 상     |
| Value         | N/A                                                   | 중     |

빅데이터 처리 및 탐색 기술은 대규모로 적재된 데이터를 대상으로 하므로 크기에 대한 처리 기술이 여전히 중요하다. 또한 데이터 후처리 작업과 정규화 과정을 통해 데이터의 진실성을 확보하고 후처리된 데이터셋을 시각화 툴로 더욱 용이하게 탐색할 수 있다.



#### 분석/응용 기술

빅데이터의 분석 기술은 대규모 데이터로부터 새로운 패턴을 찾고, 그 패턴을 해석하는 통찰력을 확보하기 위한 기술이다. 빅데이터 분석은 활용 영역에 따라 통계, 데이터 마이닝, 텍스트 마이닝, 소셜 미디어 분석, 머신러닝(딥러닝) 등 다양하게 분류된다. 

빅데이터라는 용어가 사용되기 이전에도 데이터 분석 기술과 도구가 많이 사용되고 있었지만 모바일과 소셜 네트워크 서비스, 그리고 4차 산업혁명 시기에 접어들면서 생산되는 데이터의 양을 기존 분석 기술로 처리하는 데 한계가 발생했다. 하지만 빅데이터 분석 기술은 선형적 확장이 가능했고 대규모 분산 환경을 낮은 비용으로도 구축할 수 있어 기존 분석 기술의 한계점을 극복할 수 있었다.



**[6V 관점의 빅데이터 분석/응용 기술]**

| 6V            | 분석/응용 기술                             | 중요성 |
| ------------- | ------------------------------------------ | ------ |
| Volume        | 대용량 데이터(테라바이트 이상) 분석        | 상     |
| Variety       | 정형/반정형/비정형 등의 다양한 데이터 분석 | 상     |
| Velocity      | 인메모리 기반으로 실시간 데이터 분석       | 상     |
| Veracity      | 신뢰도 높은 분석 결과를 비즈니스에 적용    | 상     |
| Visualization | 분석 결과 및 창출된 가치를 시각화          | 상     |
| Value         | 분석된 결과를 비즈니스에 적용해 가치 창출  | 상     |

빅데이터 분석/응용은 6V의 모든 항목이 적용된다. 특히 마지막 가치(Value)는 빅데이터의 구축 사이클에서 빅데이터의 치종 목표가 된다. 빅데이터 기술은 5V로 비즈니스에 대한 통찰력을 갖게 되고, 마지막에는 1V(Value)를 창출하는 도구가 되는 것이다.



### 빅데이터와 보안

#### 데이터 보안

데이터 보안은 한마디로 개인과 기업의 정보 보호를 위한 정책과 기술을 말한다. 빅데이터에서 데이터 보안의 원칙은 "개인 식별이 가능한 어떠한 정보도 수집하지 않는다"다. 개인 식별 정보란 개인을 식별할 수 있는 고유한 정보로서 이름, 직업, 성별, 주민등록번호, 전화번호, 주소, 여권번호, 위치 정보 등 매우 다양할 수 있다.하지만 이러한 개인 식별 정보를 아예 수집하지 못할 경우 빅데이터 분석 자체가 의미 없어지므로 이러한 개인 식별 정보는 다음 그림과 같이 비식별화 처리해 적재한다.



| 이름 | 연령대 | 성별 |        거주지         |  직업  |   전화번호    |
| :--: | :----: | :--: | :-------------------: | :----: | :-----------: |
| 홍** |  20대  |  남  | 서울 강남구 신사동 OO | 대학생 | 010-XXXX-1234 |
| 김** |  30대  |  여  | 경기 과천시 중앙동 OO | 공무원 | 010-XXXX-9876 |
| 이** |  40대  |  남  |  부산 중구 광복동 OO  | 자영업 | 010-XXXX-6678 |
| ...  |  ....  | .... |         ....          |  ...   |     ....      |

개인정보 비식별화 기술은 가명처리, 총계처리, 데이터 값 삭제, 범주화, 마스킹 등이 있는데 이는 빅데이터 외에도 기존의 다양한 분야에서 사용하는 시빅별화 기술이다. 이렇게 비식별화된 개인정보는 빅데이터에 적재되더라도 개인을 식별하기가 어려워 안전하게 개인의 사생활 정보를 보호할 수 있다. 하지만 이렇게 비식별화된 개인정보를 활용하는 데는 **두 가지**이슈가 있다.

<u>첫 번째</u>는 개인정보 **재식별화**다. **재식별화**란 빅데이터에 워낙 많고 다양한 데이터가 존재하다 보니 주변의 다른 데이터와 결합됐을 때 특정 개인의 식별력이 높아지는 경우를 말한다.

| 이름 | 연령대 | 성별 |        거주지         |  직업  |   전화번호    | 취미 |  차량모델  |
| :--: | :----: | :--: | :-------------------: | :----: | :-----------: | :--: | :--------: |
| 홍** |  20대  |  남  | 서울 강남구 신사동 OO | 대학생 | 010-XXXX-1234 | 게임 |     -      |
| 김** |  30대  |  여  | 경기 과천시 중앙동 OO | 공무원 | 010-XXXX-9876 | 골프 | 그랜져 2.0 |
| 이** |  40대  |  남  |  부산 중구 광복동 OO  | 자영업 | 010-XXXX-6678 | 수영 | 카니발 2.5 |
| ...  |  ...   | ...  |          ...          |  ...   |      ...      | ...  |    ...     |

기존의 비식별화된 개인정보에서 취미, 차량모델이 결합된 모습이다. 빅데이터에서 <u>취미</u>와 <u>차량정보</u>는 개인의 소셜 정보를 분석하거나 외부 도메인에서 개인정보 제공 및 활용 동의 등으로 인해 얼마든지 추가될 수 있다. 문제는 새로 결합된 취미와 차량모델로 인해 기존의 비식별화됐던 개인정보의 식별력이 높아졌다는 것이다. 다시 말해 "이**, 40대, 남성, 부산 중구 광복동 OO, 자영업, 010-XXXX-6678"로는 개인을 식별하기 위한 정보가 너무 포괄적이어서 악의적으로 이용하기가 어려웠지만 취미와 차량모델 정보가 결합되자 "성은 이 씨고, 40대 남성이면서 부산 중구 광복동에 살고, 직업이 자영업인데 카니발을 운전하면서 취미로 수영을 하는 사람" 은 실제로 유일할 수 있기 때문에 특정 개인을 식별할 가능성이 매우 높아진 것이다.



**두 번째** 이슈는 개인정보 보호로 인해 개인화된 서비스 또는 마케팅이 어려워진다는 것이다. 기업은 개인정보 활용에 동의한 고객을 대상으로 1:1 마케팅, 신용정보 스코어링, 행동이력에 따른 실시간 상품 추천 등을 수행하는데, 빅데이터 시스템은 수시로 변경되는 마케팅 동의 현황을 관리하는 게 어렵고 특정 개인을 타게팅하기 위한 고유키값이 비식별화 처리돼 있어 타깃 분석과 서비스 개발이 쉽지가 않다.

대안으로 마케팅 활용 동의 여부에 대한 정보는 관련 시스템으로부터 최대한 짧은 주기로 수집해 업데이트하고, 개인 식별 문제는 사회적 식별키(이메일, 계좌번호, 전화번호, 주민등록번호, 여권번호, 운전면허번호 등) 대신 고객관리 시스템에서 고유하게 발급하는 대체키(대표키, 고객키로도 불리며 시스템 내에 유니크한 값으로 생성)를 활용해 빅데이터에 적재된 다른 정보와 결합해 사용한다.

**ex) 대체키**

| 대체키 | 이름 | 연령대 | 성별 |        거주지         |  직업  |   전화번호    | 취미 |  차량모델  |
| :----: | :--: | :----: | :--: | :-------------------: | :----: | :-----------: | :--: | :--------: |
|  A001  | 홍** |  20대  |  남  | 서울 강남구 신사동 OO | 대학생 | 010-XXXX-1234 | 게임 |     -      |
|  A002  | 김** |  30대  |  여  | 경기 과천시 중앙동 OO | 공무원 | 010-XXXX-9876 | 골프 | 그랜져 2.0 |
|  A003  | 이** |  40대  |  남  |  부산 중구 광복동 OO  | 자영업 | 010-XXXX-6678 | 수영 | 카니발 2.5 |
|  ...   | ...  |  ...   | ...  |          ...          |  ...   |      ...      | ...  |    ...     |

빅데이터에서는 분석 결과를 이 대체키를 기준으로 제공하고, 마케팅팀, 영업팀, 리스크관리팀 등에 서는 엄격한 보안 정책에 따라 이 대체키와 매핑된 개인정보를 조회하고 활용하면서 다양한 비즈니스 활동을 수행하게 된다.



#### 접근제어 보안

빅데이터  시스템의 물리적(네트워크) 위치는 대부분 방화벽 안쪽으로 외부 공격이나 불특정 다수의 접근이 원천적으로 불가하며, 데이터는 앞서 설명한 비식별화된 데이터로 저장돼 있어 보통은 저수준의 접근제어 정책을 적용한다. 하지만 일부 금융권 및 민감한 개인정보를 다루는 빅데이터 시스템의 경우 엄격한 접근제어 정책과 보안 준수를 요구하고 있으며, 이를 해결하기 위한 기술로 아파치 녹스(Apache Knox), 아파치 센트리(Apache Sentry), 아파치 레인저(Apache Ranger), 커베로스(Kerberos)등을 활용할 수 있다.



먼저 **아파치 녹스**의 경우 네트워크상의 DMZ에 위치시킴으로써 외부 클라이언트가 하둡 에코시스템에 직접 접근하는 것을 막고, 항상 녹스를 거쳐 통신하게 하는 중간 게이트웨이 역할로 주로 사용된다. 이때 들어온 요청에 대한 접근 인증을 LDAP( Lightweight Directory Access Protocol )과 KDC(Key Distribution Center)로 제공받을 수 있다.

![image-20210401163402088](https://github.com/thinkp0907/Data_Engineering/blob/main/BigData_Skills/img/image-20210401163402088.png)

**아파치 센트리는** 하둡 파일시스템에 상세한 접근 제어(하둡 파일/디렉토리, 하이브 테이블 등)가 필요할 때 사용된다. 하둡 데이터에 접근하려는 클라이언트는 센트리 에이전트(Sentry Agent)를 반드시 설치해야 하고, 센트리 에이전트가 중앙에 있는 센트리 서버와 통신하면서 접근 권한을 획들하게 된다.

![image-20210401163958292](C:\Users\Chorlock\Data_Engineering\BigData_Skills\img\image-20210401163958292.png)



**아파치 레인저**는 앞서 설명한 세트리와 유사한 아키텍처와 역할을 가지고 있다. 아파치 레인저는 호튼웍스에서, 센트리는 클라우데라에서 지원하고 있으며, 레인저가 지원하는 에코시스템이 많아 범용성이 좀 더 높은 편이다.

레인저를 사용할 경우 플러그인을 통해 레인저 서버와 통신하게 되고 센트리와 마찬가지로 접근 이력을 관리하는 감사 로그 기능을 제공한다.

![image-20210401164402560](C:\Users\Chorlock\Data_Engineering\BigData_Skills\img\image-20210401164402560.png)



마지막으로 **커베로스**는 KDC(Key Distribution Center) 시스템으로 불리며, 빅데이터 외에도 이미 다양한 곳에서 활용되고 있는 범용화된 인증 시스템이다. 

커베로스는 크게 AS(Authentication Service)라는 인증 서버와 TGS(Ticket Granting Service)라는 티켓 발행 서버로 구성된다. 하둡 파일시스템에 접근하려는 클라이언트 에코시스템은 AS 인증 서버를 통해 최초 인증을 수행하고 TGS 티켓 발행 서버로부터 하둡 파일시스템에 접근을 허용하는 티켓을 발행받는다. 이후부터는 유효한 티켓만 있으면 하둡 파일시스템에 인증 없이 접근할 수 있다.



![image-20210401164945772](C:\Users\Chorlock\Data_Engineering\BigData_Skills\img\image-20210401164945772.png)

## Reference

출처: 실무로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지(지은이: 김강원, 펴낸곳: 위키북스)



