## 수집 파일럿 실행

### 수집 파일럿 실행 1단계 - 수집 아키텍처

#### 수집 요구사항

빅데이터 파일럿 프로젝트의 두 가지 요구사항을 다시 한번 살펴보자. 그리고 빅데이터 수집 관점에서 요구사항들을 더 구체화하고, 이를 해결하기 위한 솔루션과 기술 요소들을 도출한다.



- **요구사항 1:** 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검한다
- **요구사항 2:** 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴을 분석한다.

#### 요구사항 구체화 및 분석

| 수집 요구사항 구체화                                         | 분석 및 해결 방안                                            |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1. 스마트카로부터 로그파일들이 주기적으로 발생한다           | 플럼을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집    |
| 2. 스마트카의 배치 로그 파일 이벤트를 감지해야 한다.         | 플럼의 Source 컴포넌트 중 SpoolDir를 이용해 주기적인 로그 파일 발생 이벤트를 감지 |
| 3. 스마트카의 실시간 로그 발생 이벤트를 감지해야 한다.       | 플럼의 Source 컴포넌트 중 Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지 |
| 4. 스마트카가 만들어내는 로그 데이터에 가비지 데이터가 있을 수 있다. | 플럼의 Interceptor를 이용해 정상 패턴의 데이터만 필터링      |
| 5. 수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재 처리할 수 있어야 한다. | 플럼의 메모리 Channel 및 카프카 Broker 사용으로 로컬 디스크의 파일시스템에 수집 데이터를 임시 저장 |
| 6. 스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리를 해야 한다. | 플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송 |

**['스마트카' 프로젝트의 수집 요구사항 분석]**

#### 수집 아키텍처

수집 요구사항을 참고해서 스마트카의 빅데이터 분석을 위한 파일럿 프로젝트의 수집 아키텍처를 구성.

![image-20210408142417851](C:\Users\Chorlock\AppData\Roaming\Typora\typora-user-images\image-20210408142417851.png)**['스마트카' 로그/파일 수집 아키텍처]**

파일럿 프로젝트의 수집 아키텍처는 원천 데이터의 발생 유형에 따라 크게 2개의 레이어로 나눌 수 있다.

1. 대용량 로그 파일을 주기적으로 수집해서 표준 입출력 로거로 보여주는 플럼 에이전트 1 레이어
2. 실시간으로 발생하는 로그를 라인 다위로 수집해 카프카의 Topic에 전송하는 플럼 에이전트 2 레이어



#### 로그 시뮬레이터

스마트카의 상태 정보와 운전자의 운행 정보 로그를 가상으로 만드는 자바 로그 발생기다.

**① 스마트카 상태 정보**: 100대 스마트카 장치들의 상태 정보를 3초 간격으로 발생시키며, 1일 100MB의 로그파일이 만들어진다.

**⑥ 스마트카 운전자 운행 정보**: 100명의 스마트카 운전자들의 운행 정보를 실시간으로 발생시키며, 발생된 하나의 운행 정보 로그는 4KB 미만이다. 동시에 최대 400KB 용량으로 실시간 데이터가 발생된다.



#### 플럼 에이전트 1

스마트카 상태 정보를 기록한 로그 파일을 일별로 수집하기 위한 배치성 플럼 에이전트다.

**② SpoolDir Source:** 약속된 로그 발생 디렉터리를 모니터링하다가 정의된 로그 파일 발생 시 해당 파일의 내용을 읽어서 수집하는 기능을 제공한다.

**③ Memory Channel:** SpoolDir Source로부터 수집된 데이터를 메모리 Channel에 중간 적재한다. 버퍼링 기능을 제공하며, Sink와 연결되어 트랜잭션 처리를 지원한다.

**④ Logger Sink:** Channel로부터 읽어들인 데이터를 플럼의 표준 로그 파일로 출력하게 된다.



#### 플럼 에이전트 2

스마트카 운전자의 운행 정보를 실시간으로 수집하기 위한 실시간성 플럼 에이전트다.

**⑦ Exec-Tail Source:** 로그가 쌓이고 있는 파일에 Tail 파이프라인을 이용해 실시간으로 데이터를 수집하는 기능을 제공한다

**⑧ Memory Channel:** Exec-Tail Source로부터 수집된 데이터를 메모리 Channel에 버퍼링 처리를 하면서 임시 적재한다.

**⑨ Kafka Sink:** Channel로부터 읽어들인 데이터를 카프카 Broker의 특정 토픽에 비동기 방식으로 전송하는 Provider 역할을 수행한다.



#### 기타

플럼이 수집한 로그 데이터를 임시 출력 및 저장한다.

**⑤ Flume Stdout:** 플럼의 Logger-Sink를 통해 표준 출력 로그가 출력된다.

**⑩ Kafka Topic:** 플럼의 Kafka-Sink는 수집된 실시간 로그를 임시 적재한다.



---

### 수집 파일럿 실행 2단계 - 수집 환경 구성

Cloudera Manager를 이용해 플럼과 카프카를 Server01 가상 머신에 설치한다. 우선 플럼을 설치해 보겠다.

##### 플럼 설치

1. server01.hadoop.com:7180에 접속하여 `Cluster1` 서비스 추가 -> Flume.
2. `호스트`를 `server01.hadoop.com`으로 선택하고 설치한다.
3. Cloudera Manager 홈 -> [Flume]-> [구성]에서 검색란에 'java heap'이라고 입력하면 힙 메모리 설정창이 나타단다. 여기서 힙 크기를 "100"MiB 로 늘리고 재시작

##### 카프카 설치

1. server01.hadoop.com:7180에 접속하여 `Cluster1` 서비스 추가 -> Kafka

2. `호스트`를 `server01.hadoop.com`으로 선택하고 설치한다. (MirrorMaker, Gateway는 선택X)

3. 설치 이후, CM홈 -> [Kafka] -> [구성]에서 `Data Retention Time` 입력한 후 7일에서 10분으로 수정 해준 이후 재시작.

   

---

### 수집 파일럿 실행 3단계 - 플럼 수집 기능 구현

플럼에서는 2개의 에이전트를 구현한다.

스마트카의 상태 정보를 수집하는 `"SmartCarInfo Agent"` 와 운전자의 운행 정보를 수집하는 `"DriverCarInfo Agent"`다.

플럼의 에이전트를 만들려면 플럼이 인식할 수 있는 특정 디렉터리에 이름이 { Agent 고유이름 }.conf 형식인 파일을 생성하면 되는데, 파일럿 프로젝트에서는 CM에서 제공하는 플럼 구성 정보 설정을 통해 에이전트를 편리하게 생성할 수 있다.



구성된 최종본을 먼저 사진으로 확인하겠다

![에이전트 생성](C:\Users\Chorlock\Data_Engineering\BigData_Skills\img\에이전트 생성.png)

#### SmartCar Agent 생성

1. CM 홈 -> [Flume] -> [구성] -> "구성 파일" 검색 -> Agent 이름란에 `"SmartCar_Agent"`를 입력

2. 아래에 있는 "구성 파일"항목에 아래와 같이 작성

   >  SmartCar_Agent.sources = SmartCarInfo_SpoolSource
   >
   > SmartCar_Agent.channels = SmartCarInfo_Channel
   >
   > SmartCar_Agent.sinks = SmartCarInfo_LoggerSink

   - 플럼의 에이전트에서 사용할 Source, Channel, Sink의 각 리소스 변수를 정의한 것

   >SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
   >
   >SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
   >
   >SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
   >
   >SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000

   - 플럼 에이전트의 Source 설정. 
   - 위 에서 선언한 SmartCarInfo_SpoolSource라는 변수에 Type을 "spooldir"로 설정했다. "spooldir"는 지정한 특정 디렉터리를 모니터링하고 있다가 새로운 파일이 생성되면 이벤트를 감지해서 "batchSize"의 설정값만큼 읽어서 Channel에 데이터로 전송한다. (Channel 설정은 아래)

   > SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
   >
   > SmartCar_Agent.channels.SmartCarInfo_Channel.capacity = 100000
   >
   > SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity = 10000

   - 플럼 에이전트의 Channel로서 SmartCarInfo_Channel의 Type을 "memory"로 설정했다. 채널의 종류는 크게 `memory`와 `file`이 있다.
   - `memory channel`은 Source로부터 받은 데이터를 메모리상에 중간 적재하므로 성능이 높지만 안정성이 낮다. 반면 `file channel`의 경우 source에서 전송한 데이터를 받아 로컬 파일시스템 경로인 "dataDirs"에 임시로 저장했다가 Sink에게 데이터를 제공하므로 성능은 낮지만 안정성이 높다

   > SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger

   - 플럼 에이전트의 최종 목적지다.
   - SmartCarInfo_LoggerSink의 type을 "logger"로 설정했다. Logger Sink는 수집 한 데이터를 **테스트 및 디버깅 목적으로 플럼의 표준 출력 로그 파일인** `/var/log/flume_ng/flume_cmf-flume-AGENT-server01.hadoop.com.log`에 출력한다.

   > SmartCar_Agent.sources.SmartCarInfo_SpoolSources.channels = SmartCarInfo_Channel
   >
   > SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channels = SmartCarInfo_Channel

   - Source와 Channel Sink를 연결한다.
   - 앞서 정의한 SmartCarInfo_SpoolSource의 채널 값을 SmartCarInfo_Channel로 설정하고, SmartCarInfo_LoggerSink의 채널 값도 SmartCarInfo_Channel로 설정해서 File-> Channel -> Sink로 이어지는 에이전트 리소소를 하나로 연결해 준다.

   

   #### SmartCar 에이전트에 Interceptor 추가

   **Interceptor**는 Source와 Channel의 중간에서 **데이터를 가공하는**역할을 한다. 플럼의 Source에서 유입되는 데이터 중 일부 데이터를 수정하거나 필요한 데이터만 필터링하는 등 중간에 데이터를 추가/가공/정제하는 데 사용된다.

   플럼에서 데이터 전송 단위를 `Event` 라 하는데, `Event`의 구조는 다시 `Header`와 메시지 본문인 `Body`로 구성된다. 이때 Interceptor는 `Event`의 `Header`에 특정값을 **추가**하거나 `Event`의 `Body`에 데이터를 가공하는 기능으로 활용된다.

   

   작성한 SmartCarInfo 에이전트를 수정해서 `Filter Interceptor`를 사용해 보자.

   CM 홈 -> [Flume] -> 구성 -> "구성 파일"란에 아래 내용을 추가하고 [변경 내용 저장]

   > SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = filterInterceptor

   - 수집 데이터를 필터링하기 위해 `filterInterceptor`변수를 선언해서 SmartCarInfo_SpoolSource에 할당했다.

   > SmartCar_Agent.sources.SmartCarInfo_Spoolsource.interceptors.filterInterceptor.type = regex_filter
   >
   > SmartCar_Agent.sources.SmartCarInfo_Spoolsource.interceptors.filterInterceptor.regex = ^\\\d{14}
   >
   > SmartCar_Agent.sources.SmartCarInfo_Spoolsource.interceptors.filterInterceptor.excludeEvents = false

   - `filterInterceptor`의 Type을 "regex_filter"로 설정했다. Type명에서 알 수 있듯이 정규 표현식(Regular Expression을 이용해 수집 데이터를 필터링할 때 유용하게 사용할 수 있다.
   - '스마트카'의 로그 생성기가 만든 로그파일의 내용 중간에 로그 포맷의 형식을 알리는 메타 정보가 포함돼 있다. 이러한 메터 정보를 제외하고 필요한 데이터만 수집하기 위해 정규표현식을 사용한다.
   - 로그파일은 14자리 날짜 형식으로 시작하기 때문에 `filterInterceptor.regex = ^\\d{14}`라는 정규 표현식을 통해 14자리 날짜 정보로 시작하는 데이터만 수집한다.
   - `excludeEvents` 속성을 "true"로 하면 제외 대상만 수집하게 된다.

   

   #### DriverCar 에이전트 생성

   DriverCarInfo 에이전트는 앞서 작성한 SmartCar 에이전트에 DriverCarInfo 에이전트를 위한 Source, Channel, Sink를 추가해 생성한다.

   

   > SmartCar_Agent.sources = DriverCarInfo_TailSource
   >
   > SmartCar_Agent.channels = DriverCarInfo_Channel
   >
   > SmartCar_Agent.sinks = DriverCarInfo_KafkaSink

   - DriverCarInfo 에이전트를 위한 리로스 변수를 선언

   > SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec
   >
   > SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log
   >
   > SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
   >
   > SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000

   - Source의 Type이 "exec"다. "exec"는 플럼 외부에서 수행한 명령의 결과를 플럼의 Event로 가져와 수집할 수 있는 기능을 제공한다.
   - 스마트카 운전자의 운행 정보가 로그 시뮬레이터를 통해 `/home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log`에 생성되는데, 리눅스의 "tail" 명령을 플럼의"exec"를 실행해서 운전자의 실시간 운행 정보를 수집한다.

   > SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
   >
   > SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\\d{14}
   >
   > SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false

   - 여기서도 데이터를 필터링하기 위한 "regex_filter"만 추가했다.

   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
   >
   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
   >
   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server01.hadoop.com:9092
   >
   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
   >
   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000

   - 스마트카 운전자의 실시간 운행 정보는 플럼에서 수집과 동시에 카프카로 전송한다. 플럼의 KafkaSink의 내용을 보면 카프카 브로커 서버가 실행 중인 server01.hadoop.com:9092에 연결해서 SmartCar-Topic에 데이터를 1000개의 배치 크기로 전송한다.

   > SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
   >
   > SmartCar_Agent.channels.DriverCarInfo_Channel.capacity = 100000
   >
   > SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000

   - DriverCarInfo의 Channel을 `memory channel`로 선언했다.

   > SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
   >
   > SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel

   - DriverCarInfo의 Source와 SInk의 Channel을 앞서 정의한 DriverCarInfo_Channel로 설정해서 Source-Channel-Sink의 구조를 완성했다.



모든 에이전트 구성이 끝났다면, **[변경 내용 저장]**버튼으로 저장. 다음의 카프카 설정까지 마치고 플럼 서버 재실행.



### 수집 파일럿 실행 4단계 - 카프카 기능 구현

카프카에 대한 직접적인 기능 구현은 하지 않는다. 이미 플럼의 DriverCarInfo_KafkaSink를 통해 수집한 실시간 데이터를 카프카에 전송하는 기능 구현은 끝났기 때문이다.



여기서는 카프카의 명령어를 이용해 카프카의 브로커 안에 앞으로 사용하게 될 **토픽**을 생성하고, 카프카의 Producer 명령어를 통해 토픽에 데이터를 전송한다.



#### 카프카 Topic 생성

카프카가 설치돼 있는 Server01에서는 카프카의 CLI 명령어를 이용해 다양한 카프카 기능을 사용해 볼 수 있다. 아래의 카프카 토픽 명령어로 SmartCar-Topic을 생성한다.

```bash
$ kafka-topics --create --zookeeper server01.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic Smartcar-Topic
```

위 명령어를 실행하고 `"Created Topic SmartCar-Topic"`이라는 메시지가 나오면 토픽이 정상적으로 생성된 것이다. 토픽 생성 명령어를 보면 `--zookeeper` 옵션이 있고 카프카가 Zookeeper에 의존적이라는 것을 알 수 있는데, **토픽의 메터 정보들이 Zookeeper의 Z노드라는 곳에 만들어지고 관리된다.**

- `--replication-factor`옵션은 카프카를 다중 Broker로 만들고 전송한 데이터를 `replication-factor` 개수만큼 복제하게 되는데, 파일럿 프로젝트에서는 단일 카프카 브로커이므로 복제 개수는 1개만 설정한다.
- `partitions` 옵션은 해당 Topic에 데이터들이 partitions의 개수만큼 분리 저장하게 된다. 이 역시 다중 Broker에서 쓰기/읽기 성능 향상을 위해 사용하는 옵션이다.
- `--topic` 옵션은 파일럿 환경에서 사용할 토픽명을 정의한다. 위 명령어를 보면 `"SmartCar-Topic"`이라는 이름으로 토픽을 만드는데, 이는 **플럼의 DriverCarInfo_KafkaSink에서 설정한 토픽 이름과 같아야 한다.**

참고로 아래의 명령어로 특정 토픽을 삭제할 수 있다.

> ```bash
> $ kafka-topics --delete --zookeeper server01.hadoop.com:2181 --topic 토픽명
> ```



#### 카프카 Producer 사용

Server01에 접속하고 아래 명령을 실행해 보자.

```bash
$ kafka-console-producer --broker-list server01.hadoop.com:9092 -topic SmartCar-Topic
```

그리고 `"Hello! BigData!"` 라고 입력하고 엔터 키를 누른다. 에러 메시지가 없으면 "SmartCar-Topic"에  메시지를 성공적으로 전송한 것이다.

![image-20210411215342608](C:\Users\Chorlock\AppData\Roaming\Typora\typora-user-images\image-20210411215342608.png)



그럼 이제 아래 그림과 같은 구성으로 카프카 Producer와 Consumer 기능들을 점검해 보겠다.

![image-20210411214952033](C:\Users\Chorlock\AppData\Roaming\Typora\typora-user-images\image-20210411214952033.png)

앞서 Producer가 전송한 "Hello! BigData!" 메시지는 아직 **카프카 토픽에 머물러 있는 상태다.** Consumer 콘솔 1, 2를 실행해서 SmartCar-Topic에 연결하면 "Hello! BigData"메시지를 Consumer가 동시에 수신받게 될 것이다.



#### 카프카 Consumer 사용

Server01에 새로 SSH 터미널을 2개 열어서 각각에 아래의 카프카 Consumer 명령을 실행한다.

```bash
$ Kafka-console-consumer --bootstrap-server server01.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beiginning
```

![image-20210411215355964](C:\Users\Chorlock\AppData\Roaming\Typora\typora-user-images\image-20210411215355964.png)



Producer 콘솔창에서 메시지를 전송할 때마다 2개의 Consumer 콘솔창에 브로드케스트 되어 도일 메시지가 수신된다.



---

### 수집 파일럿 실행 5단계 - 수집 기능 테스트

지금까지 구성한 빅데이터 수집 기능 테스트

#### SmartCar 로그 시뮬레이터 작동

SmartCar의 로그 시뮬레이터를 작동시킨다. 2016년 1월 1일에 3대의 스마트카 로그만 발생시켜 보겠다

​	**1. 먼저 Server01에 SSH 접속을 하고 `bigdata.smartcart.loggen-1.0.jar`가 위치한 곳으로 이동한다.**

```bash
$ cd /home/pilot-pjt/working
```



​	**2. 다음 명령으로 2개의 스마트카 로그 시뮬레이터를 백그라운드 방식으로 실행한다.**

```bash
$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 3 &
```

```bash
$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 3 &	
```

- 2016년 1월 1일에 3대의 스마트카에 대한 상태 정보와 운전자의 운행 정보가 생성되기 시작한다.



​	**3. 정상적으로 시뮬레이터가 작동되고 있는지 아래의 내용으로 확인해 본다.**

- /home/pilot-pjt/working/SmartCar 경로에 SmartCarStatusInfo_20160101.txt 파일이 생성됐는지 확인한다. SmartCarStatusInfo_20160101.txt 파일의 내용을 확인해 보면 3대의 스마트카 상태 정보가 기록된 것을 볼 수 있다.

```bash
$ cd /home/pilot-pjt/working/SmartCar
$ vi SmartCarStatusInfo_20160101.txt
```

- /home/pilot-pjt/working/driver-realtime-log 경로에 SmartCarDriverInfo.log 파일이 생성됐는지 확인한다. tail -f SmartCarDriverInfo.log 명령을 통해 3대의 스마트카 운전자의 운행 정보가 실시간으로 발생하는 것을 볼 수 있다.

```bash
$ cd /home/pilot-pjt/working/driver-realtime-log
$ tail -f SmartCarDriverInfo.log
```



​	**4. 마지막으로 /home/pilot-pjt/working/SmartCar 경로에 만들어진 SmartCarStatusInfo_20160101.txt 파일을 플럼 SmartCarInfo 에이전트의 SpoolDir 경로로 옮긴다.**

```bash
$ mv /home/pilot-pjt/working/SmartCar/SmartCarStatusInfo_20160101.txt /home/pilot-pjt/working/car-batch-log/
```



#### 플럼 에이전트 작동

CM홈으로 이동해서 [Flume] 재시작



#### 카프카 Consumer 작동

카프카 Consumer를 작동시켜 보자. Server01에 접속해서 다음과 같은 카프카 명령을 실행시킨다. 이전에 사용한 `--from-beginning` 옵션은 생략한다. 카프카 Conumser에 `--from-beginning` 옵션을 붙이면 해당 토픽에 저장된 첫 데이터 부터 마지막 데이터 까지 일괄 수신 후 대기하게 된다. 여기서는 실시간으로 발생된 데이터만 수신할 것이므로 해당 옵션은 제외하고 실행.

```bash
$ kafka-console-consumer --bootstrap-server server01.hadoop.com:9092 --topic SmartCar-Topic --partitions 0
```

앞서 실행한 시뮬레이터에 의해 스마트카의 운행 로그 데이터가 실시간으로 카프카에 유입되는 것을 확인할 수 있다.



#### 수집 기능 점검

빅데이터 수집 기능이 정상적으로 작동하고 있는지 아래의 단계를 거쳐 확인해 보자.

**1. 스마트카의 상태 정보 로그 파일이 플럼의 표준 출력 로그로 전송됐는지 리눅스 tail 명령어를 통해 확인한다.**

```bash
$ tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-server01.hadoop.com.log
```



**2. 이제 스마트카 운전자의 실시간 운전 정보인 DriverCarInfo가 정상적으로 수집되는지 확인한다. 앞서 실행했던 Kafka의 Consumer 콘솔창을 확인해 보자.**

```bash
$ Kafka-console-consumer --bootstrap-server server01.hadoop.com:9092 --topic SmartCar-Topic --partitions 0
```



**3. 이제 백그라운드로 실행했던 스마트카 로그 시뮬레이터를 모두 종료한다.** 

```bash
$ ps -ef | grep smartcar.log
```

위 명령어로 조회된 두 자바 프로세스(CarLogMain, DriverLogMain)의 pid를 찾아 강제로 종료하자

```bash
$ kill -9 [pid]
```



---

### 파일럿 환경의 로그 확인

빅데이터 시스템에서는 에코시스템들의 로그를 확인하는 것이 중요하다. 많은 소프트웨어가 설치되고 서로간읜 의존성이 커서 다양한 문제점들을 로그를 통해 확인해야 하기 때문이다. 파일럿 환경의 로그를 점검하기 위해서는 아래의 경로들을 참고한다.

- Hadoop 에코시스템 서버들의 로그 위치: `/var/log/디렉터리(cloudera, Hadoop, Oozie 등)`
- Redis 서버 로그 위치: `/var/log/redis_6379.log`
- Storm 서버 로그 위치: `/home/pilot-pjt/storm/logs/`
- Zeppelin 서버 로그 위치: `/home/pilot-pjt/zeppelin-0.8.2-bin-all/logs`



















